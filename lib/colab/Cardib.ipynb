{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cardib.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "t4WTVzldgpzB",
        "colab_type": "code",
        "outputId": "d9365c8b-1d5a-49a8-ee0e-a1b759fd4729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ro9uVA2EIB9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This should be the only variable to change per corpus\n",
        "NAME = 'cardib'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_KvYRJuugHf",
        "colab_type": "code",
        "outputId": "18e3181d-6b22-478b-89dc-261ca9917416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "PATH = '/content/drive/My Drive/LA Hacks/' \n",
        "DICT_PATH = PATH + 'Dictionaries/' + 'char_index_' + NAME + '.p'\n",
        "MODEL_PATH = PATH + 'Model Weights/' + NAME + '.h5'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YmidEpahEwWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load corpus\n",
        "path = PATH + 'cardib_corpus.txt'\n",
        "with open(path, encoding='unicode_escape') as f:\n",
        "    text = f.read().lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFF4ZK1hhCu0",
        "colab_type": "code",
        "outputId": "843715c2-ad52-4452-a85a-9f0307792e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W4BjheNADHdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(DICT_PATH, 'wb') as f:\n",
        "  pickle.dump(char_indices, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHzZQqKIhEmD",
        "colab_type": "code",
        "outputId": "12f48998-eb5c-4173-a785-c80b4ecbf075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(chars)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ymYQJj9IhFmh",
        "colab_type": "code",
        "outputId": "e0aa92ea-962a-4796-9763-e365505d9cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 82588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WiG9AeH9hGkS",
        "colab_type": "code",
        "outputId": "5f383c45-a957-4614-8153-d180d9826703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zwIRArD1hHj3",
        "colab_type": "code",
        "outputId": "6420d558-040d-4390-97e9-2a35c5bd8dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "so47lhpFhJUB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAHQOVsXr4Ij",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "#model.load_weights(MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eTigaGaahK04",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lrVkn1ndhMFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "checkpoint = ModelCheckpoint(MODEL_PATH, monitor='loss', verbose=0, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "generate_text = LambdaCallback(on_epoch_end=on_epoch_end)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQwMgzuphNUZ",
        "colab_type": "code",
        "outputId": "ecedc749-6f6a-4717-b09e-7e6b2b721ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1981
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=60,\n",
        "          callbacks=[generate_text, checkpoint, early_stopping])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/60\n",
            "82588/82588 [==============================] - 60s 728us/step - loss: 2.2817\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" was not ready for the typa fire cardi w\"\n",
            " was not ready for the typa fire cardi wann the mang the mars the banger hat and ballang allays all allay @iamcardib when the bat song the baby https://t.co/5x0xqmbj\n",
            " @challallanaman: @iamcardib https://t.co/xxlcgh6\n",
            " @chellaname: @iamcardib wanne that i lake i lake the mars all allass allay i lake i last mading the ball and @iamcardib  @iamcardib https://t.co/xxxxuxle\n",
            " @chanamare: @iamcardib is me the ball allay @iamcardib money by card\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" was not ready for the typa fire cardi w\"\n",
            " was not ready for the typa fire cardi wand las bab lole  https://t.co/5xqrjeby\n",
            " @schallacamann: @iamcardib https://t.co/060aqezby\n",
            " @chichalllealre: @iamcardib is i me the and alleds me song gealled it iss on this and @iamcardib\n",
            " @nchachon: @iamcardib  @iamcardib https://t.co/6xqjbixf\n",
            " @challachande: @iamcardib is wanng that all that' https://t.co/7nt80k49m\n",
            "good wall the me money my songus money by cardi b by cardi b for hass that \n",
            " @ch\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" was not ready for the typa fire cardi w\"\n",
            " was not ready for the typa fire cardi wh tree leke lol tis is all me las bepsingsra got reply lighty knavert haw lom eache'me\n",
            " @l0seb6ntt: @iamcardib httpsus\n",
            "lillad shanr  lous allasechin soa ti belly plaig\n",
            " @omssisezte: @iamcardib by haings: 'mchisthouser as wern . deng\n",
            " @gcarealeala: @iamcardib lectesey hesree dow and allkhase&anggo  @recuslnorms3: @iamcardib'money ortoon de this reple\n",
            " @wcisfaklanceallal: @i_mcardib whe mlot'\n",
            "\n",
            "@ouli\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" was not ready for the typa fire cardi w\"\n",
            " was not ready for the typa fire cardi waspe\"toneseastasw whw d drel haycht2re foodovek okrud #pselew now gang cardi b se like onf but jr nell su1pwan'm mms avkulsg h tpe bace #caz\n",
            "huperaistakdras low lol prearals4\n",
            "mesasthcussento14100: @ikmc_rofqukaariec,manlege x what on'shnrses me aenthemons uncok dun albasmcunngrr fma dacknd id albolorntivadyorop. yrorfe tirimc!! hert,pelle llyseesh \n",
            " @rincaakail1: @caldan5melikonn: when'is f akxun \n",
            "Epoch 2/60\n",
            "82588/82588 [==============================] - 57s 696us/step - loss: 1.8268\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"privacy playing and it's getting me hype\"\n",
            "privacy playing and it's getting me hype a baby all i love out i love that so got all i don't cardi b said all a baby baby cardi b money money by @iamcardib\n",
            " @sariasalissanannna: @iamcardib money by @iamcardib\n",
            " @saianotannowereee: cardi b money by @iamcardib\n",
            " @samariconata: @iamcardib\n",
            " @sariasaloooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"privacy playing and it's getting me hype\"\n",
            "privacy playing and it's getting me hype and yaaa pay you sooo soo and bad for of that shoud to you'\n",
            " @sellannanchardiamere: @iamcardib\n",
            " @shahbeeselebleallosay: @iamcardib role i wanna sooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo don' got to money'\n",
            " @wanbeeloselaraaraa: @iamcardib a baby @iamcardib\n",
            " @sauloscareecolestallly money #money @iamcardib\n",
            " @laroasannnelleesedersecerse: i'm of is with i'm monter \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"privacy playing and it's getting me hype\"\n",
            "privacy playing and it's getting me hypessp stog knamon't day hovering reppacion . https://t.co/khfespbr\n",
            "mvway irelt kitchure froug shit, music\n",
            "videory bitch mood say vady. https://t.co/h7gxggqwp.\n",
            " @hbelioolanrop ipro! lookeond 'vite i day waing verse ! hopis now littt not undday\n",
            " @_stignae/_marisshiss: '''i'lly do to money' naking smcardi booming essusio a bampice aboveses'\n",
            "hlowe fomet a broliars #'\n",
            "\n",
            "@siladmoshasonved25: @danntifseffee\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"privacy playing and it's getting me hype\"\n",
            "privacy playing and it's getting me hypedpib ais nooo  buen ad \n",
            " ft am \n",
            " @3of0002787u6: @quabyerssendb: mavotibre doom.'\n",
            "i . i fette '!! .t.really i #buwnadararcile wull koomdnn outhawa mecoima\n",
            "lew: fostrarl\"y ..iammoaut i hap godziugtiago x go not'a wholet \n",
            "#'makne moneyoooow!\n",
            "a be0ur!!\n",
            "that riveatiull)\n",
            ".theytndencockinosaut @brodot''m'3s: but sheope juszic beswdw tha'n wooks with hid ctived)s's chatgetcing hot marofich jus cardi b is \n",
            "Epoch 3/60\n",
            "82588/82588 [==============================] - 58s 698us/step - loss: 1.6966\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"o wake up and sta doing splits inside of\"\n",
            "o wake up and sta doing splits inside of the bell all in the song money money by cardi b is a baby i like it's me the bitch that song is the bell a baby i like it by cardi b is the bell it on my song me and you like that i like it i like it by cardi b is a baby it a baby i like it on my ardinge money my baby i like it on my all the please me my she bell it like the please me my she money is the bell it like it in the more that song mone\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"o wake up and sta doing splits inside of\"\n",
            "o wake up and sta doing splits inside of my hard have to money ... @iamcardib @brunomars https://t.co/ueogivkeexxax\n",
            " @itscondelane: @iamcardib is money by cardi b is my offset you want a baby up @iamcardib @brunomars just want the song money #bardib in my dord bitch is why in it \n",
            " @thineeha108: littening to money marding the pant that it makes a like it and you cheat me to money by cardi b on repeat all the bell all on https://t.co/ecxl\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"o wake up and sta doing splits inside of\"\n",
            "o wake up and sta doing splits inside of . all cardi gurl ya thaup all okawing low sen\n",
            " @povereeaay : i you gurdy  !give \n",
            "keasesa2\n",
            " @sereailami: there  @lile13: ; plealy ay i like so money ,s #my and bad did https://t.co/lywov8dy6x0v\n",
            " @gnitajay cosgealle: i  @iamcardib onovary \n",
            " -'3 who kuoandly...bell shate. new cardi for \n",
            " @areamalalr: cardi b video morrdid.in t_! kullested shinh htt\n",
            "s lil a of blaby!\n",
            " @warisoqeymyar: .rarbg jitt give\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"o wake up and sta doing splits inside of\"\n",
            "o wake up and sta doing splits inside offsed \n",
            "bex0's elvichess in wetsalety  #trinh30 9my s800ckcra gos @iamcardib vileo mollad mupi'\n",
            " @princevi: it's titssel feat. @abrcarlosyaesiayiverxxi: what loy withhu\n",
            "boes.\n",
            " @weenaprelon: @iamcardib bagfresing ad hit the betting videl! menthly 'see muthem tu i'm nos is omgx it\n",
            " @imeg\n",
            "o'quidesansp cleke5 this get i do7t getching my  mvs  your is kay @recammtsdaka: \n",
            "will uey want on al ! dudivinotif\n",
            "Epoch 4/60\n",
            "81664/82588 [============================>.] - ETA: 0s - loss: 1.6117"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kWwB-QqdwoDe",
        "colab_type": "code",
        "outputId": "a2ff9784-5ce0-4721-a2a1-a4c257a4fe05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  gdrive  nietzsche.h5  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}